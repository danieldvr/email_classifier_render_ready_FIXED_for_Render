# Classificador de E-mails â€“ Produtivo x Improdutivo

AplicaÃ§Ã£o web simples em **Flask + Transformers** que:
- Classifica e-mails em **Produtivo** ou **Improdutivo** via **Zero-Shot Classification** (modelo multilÃ­ngue).
- Sugere uma **resposta automÃ¡tica** adequada.

---

## ðŸš€ Como rodar localmente (passo a passo em 1 bloco)

```bash
# 1. Clone o repositÃ³rio
git clone <URL_DO_SEU_REPOSITORIO>
cd email_classifier_app-main

# 2. Crie e ative um ambiente virtual
python -m venv .venv
# Ativar no Windows:
.venv\Scripts\activate
# Ativar no Linux/Mac:
# source .venv/bin/activate

# 3. Instale as dependÃªncias
pip install --upgrade pip
pip install -r requirements.txt

# (Opcional) Caso tenha problemas com Torch no Windows:
# pip install torch --index-url https://download.pytorch.org/whl/cpu

# 4. Execute a aplicaÃ§Ã£o
python run_local.py

# Acesse no navegador:
# http://localhost:5000


> Na primeira execuÃ§Ã£o o modelo serÃ¡ baixado automaticamente (pode levar alguns minutos).

## Deploy no Render (gratuito)

1. FaÃ§a **fork** ou envie este repositÃ³rio ao GitHub.
2. Em **render.com**, crie um **Web Service** conectando ao seu repositÃ³rio.
3. Configure:
   - **Build command**: `pip install -r requirements.txt`
   - **Start command**: `gunicorn app:app`
4. Deploy. A primeira execuÃ§Ã£o serÃ¡ mais lenta para baixar o modelo.

**Dicas de Deploy**
- Prefira regiÃµes prÃ³ximas ao Brasil para menor latÃªncia.
- Se faltar memÃ³ria, troque o modelo em `utils/nlp.py` por um mais leve:
  - `"typeform/distilbert-base-uncased-mnli"` (inglÃªs â€“ leve)
  - `"MoritzLaurer/deberta-v3-base-mnli-fever-anli"` (mÃ©dio)
- Como *fallback*, implemente regras simples se o modelo nÃ£o carregar (exemplo no cÃ³digo).

## Estrutura
```
email_classifier_app-main/
â”œâ”€ api/
â”‚  â””â”€ app.py
â”œâ”€ templates/
â”‚  â””â”€ index.html
â”œâ”€ utils/
â”‚  â”œâ”€ nlp.py
â”‚  â””â”€ pdf.py
â”œâ”€ examples/
â”‚  â”œâ”€ exemplo_produtivo.txt
â”‚  â””â”€ exemplo_improdutivo.txt
â”œâ”€ requirements.txt
â”œâ”€ run_local.py
â””â”€ render.yaml

```
